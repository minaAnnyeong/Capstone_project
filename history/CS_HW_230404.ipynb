{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j9VcNmNaHjY",
        "outputId": "b8ea1fcf-39c8-47da-928c-bbb112c7bd44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-06 01:20:34--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M   105MB/s    in 0.6s    \n",
            "\n",
            "2023-04-06 01:20:34 (105 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import packages\n",
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from PIL import Image, ImageSequence\n",
        "\n",
        "!wget   http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 # DOWNLOAD LINK\n",
        "!bunzip2 /content/shape_predictor_68_face_landmarks.dat.bz2\n",
        "datFile =  \"/content/shape_predictor_68_face_landmarks.dat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhwoRFchpcu_",
        "outputId": "a9127c92-7210-471c-e854-bd1bb4ba9f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-06 01:20:50--  https://media.tenor.com/ei_IhOGEk_YAAAAd/shinyeeun-the-glory.gif\n",
            "Resolving media.tenor.com (media.tenor.com)... 172.253.122.95, 172.253.63.95, 142.251.16.95, ...\n",
            "Connecting to media.tenor.com (media.tenor.com)|172.253.122.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 658606 (643K) [image/gif]\n",
            "Saving to: ‘/content/shinyeeun-the-glory.gif’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/shinyeeun- 100%[===================>] 643.17K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-04-06 01:20:50 (94.1 MB/s) - ‘/content/shinyeeun-the-glory.gif’ saved [658606/658606]\n",
            "\n",
            "--2023-04-06 01:20:50--  https://media.tenor.com/YZuvasRsENIAAAAd/angelina-jolie-laugh.gif\n",
            "Resolving media.tenor.com (media.tenor.com)... 172.253.122.95, 172.253.63.95, 142.251.16.95, ...\n",
            "Connecting to media.tenor.com (media.tenor.com)|172.253.122.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3178376 (3.0M) [image/gif]\n",
            "Saving to: ‘/content/three-people.gif’\n",
            "\n",
            "/content/three-peop 100%[===================>]   3.03M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-06 01:20:50 (144 MB/s) - ‘/content/three-people.gif’ saved [3178376/3178376]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get sample GIF files\n",
        "!wget --no-check-certificate \\\n",
        "  https://media.tenor.com/ei_IhOGEk_YAAAAd/shinyeeun-the-glory.gif \\\n",
        "  -O /content/shinyeeun-the-glory.gif\n",
        "!wget --no-check-certificate \\\n",
        "  https://media.tenor.com/YZuvasRsENIAAAAd/angelina-jolie-laugh.gif \\\n",
        "  -O /content/three-people.gif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RA1NdCcUdH87"
      },
      "outputs": [],
      "source": [
        "# Load the image sequence using PIL\n",
        "# gif영상 내 각 frame을 list화하여 저장\n",
        "def load_gif(file_path):\n",
        "  gif = Image.open(file_path)\n",
        "  frames = [frame.convert('RGB').copy() for frame in ImageSequence.Iterator(gif)]\n",
        "  return frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsz46JujL0Ln"
      },
      "source": [
        "dlib 라이브러리를 이용하여 image sequence 내 각 이미지에서 얼굴 랜드마크 검출하는 함수 작성\n",
        "- 랜드마크는 OpenCV 함수 내 cv2.circle 함수를 이용하여 점 찍어주기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ognpvfLfe_8V"
      },
      "outputs": [],
      "source": [
        "# Write a function for detecting facial landmarks in an image sequence using the dlib library\n",
        "def detect_landmarks_dlib(frames):\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "  landmarks_frames = [] # List where images with face landmarks are saved # 복사된 이미지 안에 68개 랜드마크 찍기\n",
        "\n",
        "  # Write the code below\n",
        "  det_faces = dlib.full_object_detections()\n",
        "  \n",
        "  for i, frame in enumerate(frames):      # 각 이미지에 대해 얼굴 탐지\n",
        "    # detect faces in img using dlib frontal face detector\n",
        "    frame_ndarray = np.array(frame)\n",
        "    dets = detector(frame_ndarray, 1)\n",
        "    # print coordiates of detected face\n",
        "    for i, d in enumerate(dets): \n",
        "      f = predictor(frame_ndarray, d)\n",
        "      det_faces.append(f)\n",
        "\n",
        "  ##############\n",
        "\n",
        "  for i, frame in enumerate(frames):\n",
        "    frame_ndarray = np.array(frame)\n",
        "    # make a copy of the input image\n",
        "    #frame_cpy = frame.copy()\n",
        "    # get i_th face information\n",
        "    f = det_faces[i]\n",
        "    for j in range(f.num_parts):\n",
        "        cv2.circle(frame_ndarray, (f.part(j).x,f.part(j).y), 2, (0, 0, 255), -1)\n",
        "    # save image with overlay\n",
        "    landmarks_frames.append(frame_ndarray)\n",
        "    # dlib.save_image(frame_cpy, f'frame_{i}.png');  \n",
        "  \n",
        "  return landmarks_frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPANzrMMMEAv"
      },
      "source": [
        "image sequence를 입력받아서 OpenCV 라이브러리를 이용하여 .mp4 포맷의 비디오로 저장하는 함수 작성\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xxuStG-AfQnj"
      },
      "outputs": [],
      "source": [
        "# 프레임 > 비디오 포맷으로 저장하는 함수 구현\n",
        "# frame 'image sequence'이므로 PIL image의 배열일 것이다.\n",
        "def save_video(frames, file_name):\n",
        "  frame_array = []\n",
        "  ####추가\n",
        "  fps = 30\n",
        "  for img in frames:\n",
        "    # ((참고)) pil이미지의 .size함수의 반환값은 (width, height), ndarray의 .shape는 (height, width, color)순으로 반환한다.\n",
        "    frame_array.append(img)\n",
        "  # cv2.VideoWriter함수 이용하여 가상의 비디오 out 형성 // cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor=None)\n",
        "  out = cv2.VideoWriter(file_name, cv2.VideoWriter_fourcc(*'DIVX'), fps, img.size, True)\n",
        "  # frames의 이미지를 비디오로 조합\n",
        "  for img in frames:\n",
        "    # OpenCV는 BRG 색상 형식, matplotlib는 RGB 색상 형식을 사용하므로, cv2.cvtColor\n",
        "    out.write(cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n",
        "  out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wed2k_YCM_Lc"
      },
      "source": [
        "위에서 작성한 함수들을 활용하여 (1) GIF 파일을 읽고 (2) 얼굴 랜드마크 검출하고 (3) 동영상으로 저장 하는 코드 작성\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VGzsnb_2fdjV"
      },
      "outputs": [],
      "source": [
        "# (1) Load the gif file using the PIL library\n",
        "file_path = '/content/shinyeeun-the-glory.gif'\n",
        "#file_path = '/content/three-people.gif'\n",
        "# 동영상 파일명\n",
        "file_name = '/content/shinyeeun-the-glory-video.mp4'\n",
        "#file_name = '/content/three-people-video.mp4'\n",
        "frames = load_gif(file_path)\n",
        "\n",
        "# (2) Use the dlib library for detecting facial landmarks in the image sequence\n",
        "landmarks_frames = detect_landmarks_dlib(frames)\n",
        "# 점이 잘 찍혔는지 한 프레임만 출력해서 확인\n",
        "#pil_image=Image.fromarray(landmarks_frames[1]) \n",
        "#pil_image.show()\n",
        "\n",
        "# (3) Save the landmark-detected image sequence as a mp4 video using the OpenCV library\n",
        "pil_landmarks_frames = []\n",
        "for i in range(len(landmarks_frames)):\n",
        "  pil_image=Image.fromarray(landmarks_frames[i])\n",
        "  pil_landmarks_frames.append(pil_image)  # 68 landmarks 찍힌 프레임들 조합해 pil이미지 시퀀스로 만들기\n",
        "save_video(pil_landmarks_frames, file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBw3e1_bNS3_"
      },
      "source": [
        "얼굴 랜드마크 검출하는 함수를 mediapipe 라이브러리를 이용해서 해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzQzAZIjs2Mo",
        "outputId": "ecfcc723-a8df-4b79-f891-366fffc7eb22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.2.1\n"
          ]
        }
      ],
      "source": [
        "# install mediapipe library\n",
        "!pip install mediapipe\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YunnF4SERvqA"
      },
      "source": [
        "mediapipe 라이브러리 \n",
        "https://google.github.io/mediapipe/solutions/face_mesh.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrC1qkqiN1Dg"
      },
      "source": [
        "mediapipe 라이브러리를 이용하여 image sequence 내 각 이미지에서 얼굴 메쉬(face mesh)를 검출하는 함수 작성\n",
        "- face mesh 검출에는 mp.solutions.face_mesh 활용\n",
        "- 검출된 mesh를 그릴 때는 mp.solutions.drawing_utils 활용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Cu75MLb01ZNZ"
      },
      "outputs": [],
      "source": [
        "# Write a function that detects face meshes in a sequence of images using the mediapipe library\n",
        "def detect_face_mesh(frames):\n",
        "  mp_face_mesh = mp.solutions.face_mesh #얼굴검출 모듈\n",
        "  mp_drawing = mp.solutions.drawing_utils # 얼굴 위에 유틸 그리는 모듈\n",
        "\n",
        "  face_mesh_frames = [] # List where images with face landmarks are saved\n",
        "\n",
        "  # Write the code below\n",
        "  # refine_landmarks < True면 눈, 코, 입술의 검출이 정교해짐\n",
        "  # static_image < True면 영상의 매 프레임마다 각각, False면 첫 프레임 얼굴검출 data로부터 뒤 프레임은 Tracking을 하여 얼굴검출함\n",
        "  # max_num < 최대로 검출할 얼굴의 개수\n",
        "  face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True, static_image_mode=True, max_num_faces=3, )\n",
        "  drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "\n",
        "  for image in frames:\n",
        "    # 얼굴 검출\n",
        "    img_np = np.array(image)\n",
        "    results = face_mesh.process(img_np)\n",
        "\n",
        "    # Face Mesh 그리기\n",
        "    for single_face_landmarks in results.multi_face_landmarks:\n",
        "      mp_drawing.draw_landmarks(\n",
        "          image=img_np,\n",
        "          landmark_list=single_face_landmarks,\n",
        "          connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "          landmark_drawing_spec=drawing_spec,\n",
        "          connection_drawing_spec=drawing_spec,\n",
        "      )\n",
        "    #이미지로 저장\n",
        "    pil_image=Image.fromarray(img_np)\n",
        "    face_mesh_frames.append(pil_image)\n",
        "\n",
        "  return face_mesh_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv1Tihw2OmKe"
      },
      "source": [
        "위에서 작성한 함수들을 활용하여 (1) GIF 파일을 읽고 (2) mediapipe 라이브러리로 face mesh 검출하고 (3) 동영상으로 저장 하는 코드 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "caaqQpxL1pND"
      },
      "outputs": [],
      "source": [
        "# (1) Load the gif file using the PIL library\n",
        "file_path = '/content/shinyeeun-the-glory.gif'\n",
        "#file_path = '/content/three-people.gif'\n",
        "# 동영상 파일명\n",
        "file_name = '/content/shinyeeun-the-glory-mp.mp4'\n",
        "#file_name = '/content/three-people-mp.mp4'\n",
        "frames = load_gif(file_path)\n",
        "\n",
        "# (2) Detect face meshes for all images in the loaded gif file using the mediapipe library\n",
        "pil_landmarks_frames = detect_face_mesh(frames)\n",
        "\n",
        "# (3) Save the face mesh detected image sequence as a mp4 video using the OpenCV library\n",
        "save_video(pil_landmarks_frames, file_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZnvI2GQPKqD"
      },
      "source": [
        "(+추가) 위 코드 작성을 모두 완료했다면, 지난 시간에 실습했던 alignment 코드를 활용해서, 본인의 얼굴에서 landmark를 검출한 후 alignment 시켜보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQnjOadamruG"
      },
      "source": [
        "참고한 코드 출처:\n",
        "\n",
        "(1) [mediapipe - Face Mesh](https://denev6.tistory.com/entry/Face-Mesh) \n",
        "\n",
        "(2) [[파이썬] MediaPipe 얼굴 그물망(Face Mesh)](https://puleugo.tistory.com/5)\n",
        "\n",
        "(3) [[ Python ] 이미지들을 동영상으로 만들기 (images -> mp4)](https://data-newbie.tistory.com/384)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
